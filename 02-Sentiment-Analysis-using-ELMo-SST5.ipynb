{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>type</th>\n",
       "      <th>Processed_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .</td>\n",
       "      <td>train</td>\n",
       "      <td>the rock is destined to be the 21st century new conan and that he going to make splash even greater than arnold schwarzenegger jean claud van damme or steven segal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer/director Peter Jackson 's expanded vision of J....</td>\n",
       "      <td>train</td>\n",
       "      <td>the gorgeously elaborate continuation of the lord of the ring trilogy is so huge that column of word can not adequately describe co writer director peter jackson expanded vision of tolkien middle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Singer/composer Bryan Adams contributes a slew of songs -- a few potential hits , a few more simply intrusive to the story -- but the whole package certainly captures the intended , er , spirit of...</td>\n",
       "      <td>train</td>\n",
       "      <td>singer composer bryan adam contributes slew of song few potential hit few more simply intrusive to the story but the whole package certainly capture the intended er spirit of the piece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>You 'd think by now America would have had enough of plucky British eccentrics with hearts of gold .</td>\n",
       "      <td>train</td>\n",
       "      <td>you think by now america would have had enough of plucky british eccentric with heart of gold wouldhave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>train</td>\n",
       "      <td>yet the act is still charming here</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                                                                   ...                                                                                                                                                                                                                                                                                           Processed_Reviews\n",
       "0           0                                                                                                   ...                                                                                                                                         the rock is destined to be the 21st century new conan and that he going to make splash even greater than arnold schwarzenegger jean claud van damme or steven segal\n",
       "1           1                                                                                                   ...                                                                                                     the gorgeously elaborate continuation of the lord of the ring trilogy is so huge that column of word can not adequately describe co writer director peter jackson expanded vision of tolkien middle ...\n",
       "2           2                                                                                                   ...                                                                                                                    singer composer bryan adam contributes slew of song few potential hit few more simply intrusive to the story but the whole package certainly capture the intended er spirit of the piece\n",
       "3           3                                                                                                   ...                                                                                                                                                                                                     you think by now america would have had enough of plucky british eccentric with heart of gold wouldhave\n",
       "4           4                                                                                                   ...                                                                                                                                                                                                                                                                          yet the act is still charming here\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(r\"../input/sst5-dataset/SST5_master_train.csv\")\n",
    "# df_train.Processed_Reviews = df_train.Processed_Reviews.astype(str)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>type</th>\n",
       "      <th>Processed_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9645</td>\n",
       "      <td>4</td>\n",
       "      <td>It 's a lovely film with lovely performances by Buy and Accorsi .</td>\n",
       "      <td>test</td>\n",
       "      <td>it lovely film with lovely performance by buy and accorsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9646</td>\n",
       "      <td>3</td>\n",
       "      <td>No one goes unindicted here , which is probably for the best .</td>\n",
       "      <td>test</td>\n",
       "      <td>no one go unindicted here which is probably for the best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9647</td>\n",
       "      <td>4</td>\n",
       "      <td>And if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .</td>\n",
       "      <td>test</td>\n",
       "      <td>and if you re not nearly moved to tear by couple of scene you ve got ice water in your vein ifyou youve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9648</td>\n",
       "      <td>5</td>\n",
       "      <td>A warm , funny , engaging film .</td>\n",
       "      <td>test</td>\n",
       "      <td>warm funny engaging film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9649</td>\n",
       "      <td>5</td>\n",
       "      <td>Uses sharp humor and insight into human nature to examine class conflict , adolescent yearning , the roots of friendship and sexual identity .</td>\n",
       "      <td>test</td>\n",
       "      <td>us sharp humor and insight into human nature to examine class conflict adolescent yearning the root of friendship and sexual identity insightinto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                                        ...                                                                                                                                                                                                          Processed_Reviews\n",
       "0        9645                                                                        ...                                                                                                                                                                  it lovely film with lovely performance by buy and accorsi\n",
       "1        9646                                                                        ...                                                                                                                                                                   no one go unindicted here which is probably for the best\n",
       "2        9647                                                                        ...                                                                                                                    and if you re not nearly moved to tear by couple of scene you ve got ice water in your vein ifyou youve\n",
       "3        9648                                                                        ...                                                                                                                                                                                                   warm funny engaging film\n",
       "4        9649                                                                        ...                                                                          us sharp humor and insight into human nature to examine class conflict adolescent yearning the root of friendship and sexual identity insightinto\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(r\"../input/sst5-dataset/SST5_master_test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "train_df[\"text\"] = df_train[\"Processed_Reviews\"]\n",
    "train_df[\"label\"] = df_train['label']\n",
    "train_df['text'] = train_df['text'].astype(str)\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"text\"] = df_test[\"Processed_Reviews\"]\n",
    "test_df[\"label\"] = df_test['label']\n",
    "test_df['text'] = test_df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                rock destined 21st century new conan going make splash even greater arnold schwarzenegger jean claud van damme steven segal\n",
       "1    gorgeously elaborate continuation lord ring trilogy huge column word adequately describe co writer director peter jackson expanded vision tolkien middle earth cowriter\n",
       "2                             singer composer bryan adam contributes slew song potential hit simply intrusive story whole package certainly capture intended er spirit piece\n",
       "3                                                                                                   think america would enough plucky british eccentric heart gold wouldhave\n",
       "4                                                                                                                                                     yet act still charming\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "train_df['text'] = train_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train_df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                    lovely film lovely performance buy accorsi\n",
       "1                                                                                               one go unindicted probably best\n",
       "2                                                                 nearly moved tear couple scene got ice water vein ifyou youve\n",
       "3                                                                                                      warm funny engaging film\n",
       "4    us sharp humor insight human nature examine class conflict adolescent yearning root friendship sexual identity insightinto\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text'] = test_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "test_df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq = pd.Series(' '.join(train_df['text']).split()).value_counts()[-10:]\n",
    "# train_df['text'] = train_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "# train_df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq = pd.Series(' '.join(test_df['text']).split()).value_counts()[-10:]\n",
    "# test_df['text'] = test_df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "# test_df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Sentence to Elmo Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(train_df['label'])\n",
    "x = list(train_df['text'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "\n",
    "x_enc = x\n",
    "y_enc = encode(le, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(test_df['label'])\n",
    "x_test = list(test_df['text'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_test)\n",
    "\n",
    "x_test_enc = x_test\n",
    "y_test_enc = encode(le, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(np.asarray(x_enc), np.asarray(y_enc), test_size=0.2, random_state=42)\n",
    "# x_train = np.asarray(x_enc)\n",
    "# y_train = np.asarray(y_enc)\n",
    "\n",
    "x_test = np.asarray(x_test_enc)\n",
    "y_test = np.asarray(y_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Keras neural model with ELMO Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7716 samples, validate on 1929 samples\n",
      "Epoch 1/5\n",
      "7716/7716 [==============================] - 32s 4ms/step - loss: 1.4744 - acc: 0.3463 - val_loss: 1.3663 - val_acc: 0.4215\n",
      "Epoch 2/5\n",
      "7716/7716 [==============================] - 20s 3ms/step - loss: 1.3114 - acc: 0.4330 - val_loss: 1.3279 - val_acc: 0.4298\n",
      "Epoch 3/5\n",
      "7716/7716 [==============================] - 20s 3ms/step - loss: 1.2619 - acc: 0.4649 - val_loss: 1.3292 - val_acc: 0.4158\n",
      "Epoch 4/5\n",
      "7716/7716 [==============================] - 19s 3ms/step - loss: 1.2301 - acc: 0.4852 - val_loss: 1.3814 - val_acc: 0.3935\n",
      "Epoch 5/5\n",
      "7716/7716 [==============================] - 20s 3ms/step - loss: 1.2046 - acc: 0.4951 - val_loss: 1.3252 - val_acc: 0.4038\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def ELMoEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "\n",
    "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "\n",
    "pred = Dense(5, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=5, batch_size=128, verbose= True, validation_data= (x_val, y_val))\n",
    "    \n",
    "    model.save_weights('.elmo-model.h5')\n",
    "    \n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Time:   2 min  7 s\n"
     ]
    }
   ],
   "source": [
    "def convertTime(seconds):\n",
    "    # Function to Convert Seconds into Hours, Minutes and Seconds\n",
    "    seconds = seconds % (24 * 3600) \n",
    "    hour = seconds // 3600\n",
    "    seconds %= 3600\n",
    "    minutes = seconds // 60\n",
    "    seconds %= 60\n",
    "    \n",
    "    if(hour == 0):\n",
    "        return \"{0:2.0f} min {1:2.0f} s\".format(minutes, seconds) \n",
    "    \n",
    "    elif(hour == 0 and minutes == 0):\n",
    "        return \"{1:2.0f} s\".format(seconds) \n",
    "    \n",
    "    else:\n",
    "        return \"{0:2.0f} h {1:2.0f} min {2:2.0f} s\".format(hour, minutes, seconds)\n",
    "\n",
    "duration_Pretraining_sec = t1-t0\n",
    "duration_Pretraining = convertTime(t1 - t0)\n",
    "\n",
    "print(\"\\nTraining Time: \", duration_Pretraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ELMO is: 0.45776566757493187\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model.load_weights('./elmo-model.h5')  \n",
    "    \n",
    "    predicts = model.predict(x_test)\n",
    "\n",
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)\n",
    "\n",
    "print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14  99   2  19   5]\n",
      " [  4 207  11  59   8]\n",
      " [  2 103  29  85  10]\n",
      " [  2  54   3 179  41]\n",
      " [  0  14   4  72  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.10      0.17       139\n",
      "           2       0.43      0.72      0.54       289\n",
      "           3       0.59      0.13      0.21       229\n",
      "           4       0.43      0.64      0.52       279\n",
      "           5       0.54      0.45      0.49       165\n",
      "\n",
      "   micro avg       0.46      0.46      0.46      1101\n",
      "   macro avg       0.53      0.41      0.39      1101\n",
      "weighted avg       0.51      0.46      0.41      1101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(classification_report(y_test, y_test_predicted))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ner_elmo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "name": "NER-Tutorial",
    "notebookId": 3359671281044291
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZhJcUl06r8w"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_elmo.ipynb)\n",
        "\n",
        "## 0. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "22mElNLo6rUI",
        "outputId": "88728735-fa24-4d6a-a876-009b01c86334"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_275\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_275-8u275-b01-0ubuntu1~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.275-b01, mixed mode)\n",
            "Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.7\n",
            "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "py4j",
                  "pyspark"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting spark-nlp\n",
            "  Using cached https://files.pythonhosted.org/packages/c6/1d/9a2a7c17fc3b3aa78b3921167feed4911d5a055833fea390e7741bba0870/spark_nlp-2.6.5-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "com",
                  "sparknlp"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_QE6hqA4WHh"
      },
      "source": [
        "# How to train a NER classifier with ELMO embeddings based on Char CNNs - BiLSTM - CRF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wybDus1P4WHk"
      },
      "source": [
        "## Download the file into the local File System \n",
        "### It is a standard conll2003 format training file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA0QHrLF4WHl",
        "outputId": "bf1c4775-eb22-4543-b50f-be4a56744c43"
      },
      "source": [
        "# Download CoNLL 2003 Dataset\n",
        "import os\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "download_path = \"./eng.train\"\n",
        "\n",
        "\n",
        "if not Path(download_path).is_file():\n",
        "    print(\"File Not found will downloading it!\")\n",
        "    url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.train\"\n",
        "    urllib.request.urlretrieve(url, download_path)\n",
        "else:\n",
        "    print(\"File already present.\")\n",
        "    \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File already present.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYZhNUVH4WHs"
      },
      "source": [
        "# Read CoNLL Dataset into Spark dataframe and automagically generate features for futures tasks\n",
        "The readDataset method of the CoNLL class handily adds all the features required in the next steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQExmc684WHu",
        "outputId": "318b3469-4360-4f3c-8190-b422f7a916e2"
      },
      "source": [
        "import sparknlp\n",
        "from sparknlp.training import CoNLL\n",
        "\n",
        "spark = sparknlp.start()\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "training_data.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
            "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
            "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
            "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
            "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|\n",
            "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|\n",
            "|Spanish Farm Mini...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 6, Sp...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|                   .|[[document, 0, 0,...|[[document, 0, 0,...|[[token, 0, 0, .,...|[[pos, 0, 0, ., [...|[[named_entity, 0...|\n",
            "|Only France and B...|[[document, 0, 52...|[[document, 0, 52...|[[token, 0, 3, On...|[[pos, 0, 3, RB, ...|[[named_entity, 0...|\n",
            "|The EU 's scienti...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
            "|Sheep have long b...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 4, Sh...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "|British farmers d...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Br...|[[pos, 0, 6, JJ, ...|[[named_entity, 0...|\n",
            "|\" What we have to...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
            "|Bonn has led effo...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 3, Bo...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
            "|Germany imported ...|[[document, 0, 84...|[[document, 0, 84...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|It brought in 4,2...|[[document, 0, 82...|[[document, 0, 82...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF9dJWoW4WH6"
      },
      "source": [
        "# Define the NER Pipeline \n",
        "\n",
        "### This pipeline defines a pretrained elmo component and a trainable NerDLApproach which is based on the Char CNN - BiLSTM - CRF\n",
        "\n",
        "Usually you have to add additional pipeline components before the elmo for the document, sentence and token columns. But CoNLL took already care of this for us, awesome!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0xFttkH4WH7",
        "outputId": "86d43a71-44e9-4a69-dc53-e2daea1482c1"
      },
      "source": [
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "# Define the pretrained Elmo model. \n",
        "# We need to set lstm_outputs2 pooling layer, because the elmo layer is not yet compatible with NerDL\n",
        "elmo = ElmoEmbeddings.pretrained().setPoolingLayer(\"lstm_outputs2\") \\\n",
        " .setInputCols(\"sentence\", \"token\")\\\n",
        " .setOutputCol(\"elmo\")\\\n",
        "\n",
        "\n",
        "# Defien the Char CNN - BiLSTM - CRF model. We will feed it the Elmo tokens \n",
        "nerTagger = NerDLApproach()\\\n",
        "  .setInputCols([\"sentence\", \"token\", \"elmo\"])\\\n",
        "  .setLabelColumn(\"label\")\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setMaxEpochs(1)\\\n",
        "  .setRandomSeed(0)\\\n",
        "  .setVerbose(0)\n",
        "\n",
        "# put everything into the pipe\n",
        "pipeline = Pipeline(stages = [elmo , nerTagger])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elmo download started this may take some time.\n",
            "Approximate size to download 334.1 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpcIr8b_4WIB"
      },
      "source": [
        "# Fit the Pipeline and get results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDKsFDRy4WIC"
      },
      "source": [
        "elmo_model = pipeline.fit(training_data.limit(10))\n",
        "# elmo_model = pipeline.fit(training_data).transform(training_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pM7okzlzd0f"
      },
      "source": [
        "elmo_model.stages[1].write().save('NER_elmo_20200221')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW7bDHKd_euY"
      },
      "source": [
        "loaded_ner_model = NerDLModel.load(\"NER_elmo_20200221\")\\\r\n",
        "   .setInputCols([\"sentence\", \"token\", \"elmo\"])\\\r\n",
        "   .setOutputCol(\"ner\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh7rNYyN_jOL"
      },
      "source": [
        "document = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\r\n",
        "sentence = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\r\n",
        "token = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQmEUr3XAFFY",
        "outputId": "5f14ab13-7504-45fe-86c1-cefa4456785f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "elmo = ElmoEmbeddings.pretrained().setPoolingLayer(\"lstm_outputs2\") \\\r\n",
        " .setInputCols(\"sentence\", \"token\")\\\r\n",
        " .setOutputCol(\"elmo\")\\"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elmo download started this may take some time.\n",
            "Approximate size to download 334.1 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLjvLYEAPy3"
      },
      "source": [
        "loaded_ner_model = NerDLModel.load(\"NER_elmo_20200221\")\\\r\n",
        "   .setInputCols([\"sentence\", \"token\", \"elmo\"])\\\r\n",
        "   .setOutputCol(\"ner\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiUKCDZwAk2H"
      },
      "source": [
        "converter = NerConverter()\\\r\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\r\n",
        "    .setOutputCol(\"ner_span\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itm8mNArAa0G"
      },
      "source": [
        "custom_ner_pipeline = Pipeline(\r\n",
        "    stages = [\r\n",
        "              document,\r\n",
        "              sentence,\r\n",
        "              token,\r\n",
        "              elmo,\r\n",
        "              loaded_ner_model,\r\n",
        "              converter\r\n",
        "    ]\r\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSKuv-x4WIH"
      },
      "source": [
        "### Checkout only result columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObW2xBPn4WII"
      },
      "source": [
        "# ner_df.select(*['text', 'ner']).limit(1).show(truncate=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAGIS-vS4WIO"
      },
      "source": [
        "text = \"Peter Parker is a nice man and lives in New York\"\r\n",
        "prediction_data = spark.createDataFrame([[text]]).toDF(\"text\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7zKnSsfAvqb",
        "outputId": "3083ee78-a8f1-46f6-b044-4448fe7c7ec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prediction_model = custom_ner_pipeline.fit(prediction_data)\r\n",
        "preds = prediction_model.transform(prediction_data)\r\n",
        "preds.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                elmo|                 ner|            ner_span|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter Parker is a...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 4, Pe...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 0, 4, Pe...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnukZZ-CvSH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3go6kSqrC3VQ",
        "outputId": "175079e6-e841-4b54-d107-5055b898bf4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "preds.select(\"token.result\",\"ner.result\").show(truncate=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------+-----------------------------------------+\n",
            "|result                                                      |result                                   |\n",
            "+------------------------------------------------------------+-----------------------------------------+\n",
            "|[Peter, Parker, is, a, nice, man, and, lives, in, New, York]|[I-PER, O, O, I-PER, O, O, O, O, O, O, O]|\n",
            "+------------------------------------------------------------+-----------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOSh2klXA1vB",
        "outputId": "a6a73469-e899-48f8-fca2-f7ddf0ef9f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pyspark.sql.functions as F\r\n",
        "preds.select(F.explode(F.arrays_zip(\"ner_span.result\", \"ner_span.metadata\")).alias(\"entities\"))\\\r\n",
        ".select(F.expr(\"entities['0']\").alias(\"chunk\"), F.expr(\"entities['1'].entity\").alias(\"entity\")).\\\r\n",
        "show(truncate=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|chunk|entity|\n",
            "+-----+------+\n",
            "|Peter|PER   |\n",
            "|a    |PER   |\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA6K8AR_CUSu",
        "outputId": "5989eece-78c1-45a7-bc9a-cc8580d81160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Download CoNLL 2003 Dataset\r\n",
        "import os\r\n",
        "from pathlib import Path\r\n",
        "import urllib.request\r\n",
        "\r\n",
        "\r\n",
        "download_path = \"./eng.testa\"\r\n",
        "\r\n",
        "\r\n",
        "if not Path(download_path).is_file():\r\n",
        "    print(\"File Not found will downloading it!\")\r\n",
        "    url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.testa\"\r\n",
        "    urllib.request.urlretrieve(url, download_path)\r\n",
        "else:\r\n",
        "    print(\"File already present.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Not found will downloading it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n64AWt3OP3Bm",
        "outputId": "c8556fa3-830a-4bcd-cd51-57279dd225b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sparknlp\r\n",
        "from sparknlp.training import CoNLL\r\n",
        "spark = sparknlp.start()\r\n",
        "test_data = CoNLL().readDataset(spark, './eng.testa')\r\n",
        "test_data.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|\n",
            "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
            "|Their stay on top...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 4, Th...|[[pos, 0, 4, PRP$...|[[named_entity, 0...|\n",
            "|After bowling Som...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|\n",
            "|Trailing by 213 ,...|[[document, 0, 12...|[[document, 0, 12...|[[token, 0, 7, Tr...|[[pos, 0, 7, VBG,...|[[named_entity, 0...|\n",
            "|Essex , however ,...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 4, Es...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "|Hussain , conside...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 6, Hu...|[[pos, 0, 6, NN, ...|[[named_entity, 0...|\n",
            "|By the close York...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|\n",
            "|At the Oval , Sur...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 1, At...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|\n",
            "|He was well backe...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
            "|Derbyshire kept u...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 9, De...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|\n",
            "|Australian Tom Mo...|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 9, Au...|[[pos, 0, 9, NNP,...|[[named_entity, 0...|\n",
            "|After the frustra...|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|\n",
            "|They were held up...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 3, Th...|[[pos, 0, 3, PRP,...|[[named_entity, 0...|\n",
            "|By stumps Kent ha...|[[document, 0, 41...|[[document, 0, 41...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|\n",
            "|CRICKET - ENGLISH...|[[document, 0, 45...|[[document, 0, 45...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|\n",
            "|Result and close ...|[[document, 0, 81...|[[document, 0, 81...|[[token, 0, 5, Re...|[[pos, 0, 5, NN, ...|[[named_entity, 0...|\n",
            "|Leicester : Leice...|[[document, 0, 67...|[[document, 0, 67...|[[token, 0, 8, Le...|[[pos, 0, 8, JJ, ...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9VYbNWeRFLj",
        "outputId": "5479fe7d-7c94-4e58-b697-f6fbcb49916b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_preds = prediction_model.transform(test_data)\r\n",
        "test_preds.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|                elmo|                 ner|            ner_span|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|Their stay on top...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 4, Th...|[[pos, 0, 4, PRP$...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|After bowling Som...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|Trailing by 213 ,...|[[document, 0, 12...|[[document, 0, 12...|[[token, 0, 7, Tr...|[[pos, 0, 7, VBG,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 31, 31, ...|\n",
            "|Essex , however ,...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 4, Es...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|Hussain , conside...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 6, Hu...|[[pos, 0, 6, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|By the close York...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|At the Oval , Sur...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 1, At...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 3, 5, th...|\n",
            "|He was well backe...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|Derbyshire kept u...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 9, De...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|Australian Tom Mo...|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 9, Au...|[[pos, 0, 9, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 113, 113...|\n",
            "|After the frustra...|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 6, 8, th...|\n",
            "|They were held up...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 3, Th...|[[pos, 0, 3, PRP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 15, 16, ...|\n",
            "|By stumps Kent ha...|[[document, 0, 41...|[[document, 0, 41...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|CRICKET - ENGLISH...|[[document, 0, 45...|[[document, 0, 45...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|Result and close ...|[[document, 0, 81...|[[document, 0, 81...|[[token, 0, 5, Re...|[[pos, 0, 5, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "|Leicester : Leice...|[[document, 0, 67...|[[document, 0, 67...|[[token, 0, 8, Le...|[[pos, 0, 8, JJ, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbMheh0vPflA",
        "outputId": "38a443c3-2447-4bc1-96c1-ea9918d1717d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_preds.select(\"token.result\",\"ner.result\").show(truncate=False)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                                                                                                        |result                                                                                                                         |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, TOP, AFTER, INNINGS, VICTORY, .]                                                                                                                                                                                 |[O, O, O, O, O, O, O, O, O, O, O]                                                                                              |\n",
            "|[LONDON, 1996-08-30]                                                                                                                                                                                                                                          |[O, O]                                                                                                                         |\n",
            "|[West, Indian, all-rounder, Phil, Simmons, took, four, for, 38, on, Friday, as, Leicestershire, beat, Somerset, by, an, innings, and, 39, runs, in, two, days, to, take, over, at, the, head, of, the, county, championship, .]                               |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                      |\n",
            "|[Their, stay, on, top, ,, though, ,, may, be, short-lived, as, title, rivals, Essex, ,, Derbyshire, and, Surrey, all, closed, in, on, victory, while, Kent, made, up, for, lost, time, in, their, rain-affected, match, against, Nottinghamshire, .]          |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                |\n",
            "|[After, bowling, Somerset, out, for, 83, on, the, opening, morning, at, Grace, Road, ,, Leicestershire, extended, their, first, innings, by, 94, runs, before, being, bowled, out, for, 296, with, England, discard, Andy, Caddick, taking, three, for, 83, .]|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]             |\n",
            "|[Trailing, by, 213, ,, Somerset, got, a, solid, start, to, their, second, innings, before, Simmons, stepped, in, to, bundle, them, out, for, 174, .]                                                                                                          |[O, O, O, O, O, O, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                   |\n",
            "|[Essex, ,, however, ,, look, certain, to, regain, their, top, spot, after, Nasser, Hussain, and, Peter, Such, gave, them, a, firm, grip, on, their, match, against, Yorkshire, at, Headingley, .]                                                             |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                     |\n",
            "|[Hussain, ,, considered, surplus, to, England, ', s, one-day, requirements, ,, struck, 158, ,, his, first, championship, century, of, the, season, ,, as, Essex, reached, 372, and, took, a, first, innings, lead, of, 82, .]                                 |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                      |\n",
            "|[By, the, close, Yorkshire, had, turned, that, into, a, 37-run, advantage, but, off-spinner, Such, had, scuttled, their, hopes, ,, taking, four, for, 24, in, 48, balls, and, leaving, them, hanging, on, 119, for, five, and, praying, for, rain, .]         |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]          |\n",
            "|[At, the, Oval, ,, Surrey, captain, Chris, Lewis, ,, another, man, dumped, by, England, ,, continued, to, silence, his, critics, as, he, followed, his, four, for, 45, on, Thursday, with, 80, not, out, on, Friday, in, the, match, against, Warwickshire, .]|[O, I-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]|\n",
            "|[He, was, well, backed, by, England, hopeful, Mark, Butcher, who, made, 70, as, Surrey, closed, on, 429, for, seven, ,, a, lead, of, 234, .]                                                                                                                  |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                    |\n",
            "|[Derbyshire, kept, up, the, hunt, for, their, first, championship, title, since, 1936, by, reducing, Worcestershire, to, 133, for, five, in, their, second, innings, ,, still, 100, runs, away, from, avoiding, an, innings, defeat, .]                       |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                         |\n",
            "|[Australian, Tom, Moody, took, six, for, 82, but, Chris, Adams, ,, 123, ,, and, Tim, O'Gorman, ,, 109, ,, took, Derbyshire, to, 471, and, a, first, innings, lead, of, 233, .]                                                                                |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-PER, O, O, O, O, O, O]                              |\n",
            "|[After, the, frustration, of, seeing, the, opening, day, of, their, match, badly, affected, by, the, weather, ,, Kent, stepped, up, a, gear, to, dismiss, Nottinghamshire, for, 214, .]                                                                       |[O, I-LOC, O, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                   |\n",
            "|[They, were, held, up, by, a, gritty, 84, from, Paul, Johnson, but, ex-England, fast, bowler, Martin, McCague, took, four, for, 55, .]                                                                                                                        |[O, O, O, I-LOC, O, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                     |\n",
            "|[By, stumps, Kent, had, reached, 108, for, three, .]                                                                                                                                                                                                          |[O, O, O, O, O, O, O, O, O]                                                                                                    |\n",
            "|[CRICKET, -, ENGLISH, COUNTY, CHAMPIONSHIP, SCORES, .]                                                                                                                                                                                                        |[O, O, O, O, O, O, O]                                                                                                          |\n",
            "|[LONDON, 1996-08-30]                                                                                                                                                                                                                                          |[O, O]                                                                                                                         |\n",
            "|[Result, and, close, of, play, scores, in, English, county, championship, matches, on, Friday, :]                                                                                                                                                             |[O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                                                     |\n",
            "|[Leicester, :, Leicestershire, beat, Somerset, by, an, innings, and, 39, runs, .]                                                                                                                                                                             |[O, O, O, O, O, O, O, O, O, O, O, O]                                                                                           |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRJjn77qPzL-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
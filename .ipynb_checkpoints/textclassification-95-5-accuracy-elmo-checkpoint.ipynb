{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This kernel is based on the work of http://hunterheidenreich.com/blog/elmo-word-vectors-in-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. # 1. Kernel Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Defination :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In today world** Text Classification/Segmentation/Categorization** (for example ticket categorization in a call centre, email classification, logs category detection etc.) is a common task. With humongous data out there, its nearly impossible to do this manually. Let's try to solve this problem automatically using machine learning and natural language processing tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BBC articles dataset(2126 records) consist of two features text and the assiciated categories namely \n",
    "1. Sport \n",
    "2. Business \n",
    "3. Politics \n",
    "4. Tech \n",
    "5. Others\n",
    "\n",
    "**Our task is to train a multiclass classification model on the mentioned dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** - Classification accuracy is the number of correct predictions made as a\n",
    "ratio of all predictions made\n",
    "\n",
    "**Precision** - precision (also called positive predictive value) is the fraction of\n",
    "relevant instances among the retrieved instances\n",
    "\n",
    "**F1_score** - considers both the precision and the recall of the test to compute the\n",
    "score\n",
    "\n",
    "**Recall** â€“ recall (also known as sensitivity) is the fraction of relevant instances that\n",
    "have been retrieved over the total amount of relevant instances\n",
    "\n",
    "**Why these metrics?** - We took Accuracy, Precision, F1 Score and Recall as metrics\n",
    "for evaluating our model because accuracy would give an estimate of correct prediction. Precision would give us an estimate about the positive category predicted value i.e. how much our model is giving relevant result. F1 Score gives a clubbed estimate of precision and recall.Recall would provide us the relevant positive category prediction to the false negative and true positive category recognition results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Machine Learning Model Considered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using **ELMO embeddings with KERAS** for this use case. \n",
    "\n",
    "ELMO and KERAS is not in the scope of this kernal. Kindly refer other external sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(r\"../input/sst5-dataset/SST5_master_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>type</th>\n",
       "      <th>Processed_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>train</td>\n",
       "      <td>the rock is destined to be the 21st century ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>train</td>\n",
       "      <td>the gorgeously elaborate continuation of the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
       "      <td>train</td>\n",
       "      <td>singer composer bryan adam contributes slew of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>You 'd think by now America would have had eno...</td>\n",
       "      <td>train</td>\n",
       "      <td>you think by now america would have had enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Yet the act is still charming here .</td>\n",
       "      <td>train</td>\n",
       "      <td>yet the act is still charming here</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        ...                                                          Processed_Reviews\n",
       "0           0                        ...                          the rock is destined to be the 21st century ne...\n",
       "1           1                        ...                          the gorgeously elaborate continuation of the l...\n",
       "2           2                        ...                          singer composer bryan adam contributes slew of...\n",
       "3           3                        ...                          you think by now america would have had enough...\n",
       "4           4                        ...                                         yet the act is still charming here\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data.rename(columns={\"Processed_Reviews\":\"text\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2 Map Textual labels to numeric using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     object\n",
       "label     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df2 = pd.DataFrame()\n",
    "df2[\"text\"] = data[\"Processed_Reviews\"]\n",
    "df2[\"label\"] = data['label']\n",
    "df2['text'] = df2['text'].astype(str)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    rock destined 21st century new conan going mak...\n",
       "1    gorgeously elaborate continuation lord ring tr...\n",
       "2    singer composer bryan adam contributes slew so...\n",
       "3    think america would enough plucky british ecce...\n",
       "4                               yet act still charming\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df2['text'] = df2['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df2['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rock destined 21st century new conan going mak...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gorgeously elaborate continuation lord ring tr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singer composer bryan adam contributes slew so...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>think america would enough plucky british ecce...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yet act still charming</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  rock destined 21st century new conan going mak...      4\n",
       "1  gorgeously elaborate continuation lord ring tr...      5\n",
       "2  singer composer bryan adam contributes slew so...      4\n",
       "3  think america would enough plucky british ecce...      3\n",
       "4                             yet act still charming      4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rock destined 21st century new conan going mak...\n",
       "1    gorgeously elaborate continuation lord ring tr...\n",
       "2    singer composer bryan adam contributes slew so...\n",
       "3    think america would enough plucky british ecce...\n",
       "4                               yet act still charming\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(df2['text']).split()).value_counts()[-10:]\n",
    "df2['text'] = df2['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df2['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3 Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1215 23:08:07.414207 139775319913856 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "W1215 23:08:33.904659 139775319913856 deprecation.py:323] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "embed = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.4 Convert Sentence to Elmo Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y = list(df2['label'])\n",
    "x = list(df2['text'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "\n",
    "x_enc = x\n",
    "y_enc = encode(le, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5 Divide dataset to test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.asarray(x_enc), np.asarray(y_enc), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7716,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5 Train Keras neural model with ELMO Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7716/7716 [==============================] - 18s 2ms/step - loss: 1.4521 - acc: 0.3603\n",
      "Epoch 2/5\n",
      "7716/7716 [==============================] - 16s 2ms/step - loss: 1.3113 - acc: 0.4361\n",
      "Epoch 3/5\n",
      "7716/7716 [==============================] - 16s 2ms/step - loss: 1.2633 - acc: 0.4699\n",
      "Epoch 4/5\n",
      "7716/7716 [==============================] - 15s 2ms/step - loss: 1.2224 - acc: 0.4808\n",
      "Epoch 5/5\n",
      "7716/7716 [==============================] - 16s 2ms/step - loss: 1.1933 - acc: 0.4974\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-fb1d872d6344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-6093c663f0a8>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(le, one_hot)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def ELMoEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "\n",
    "pred = Dense(5, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(x_train, y_train, epochs=5, batch_size=128)\n",
    "    model.save_weights('./elmo-model.h5')\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model.load_weights('./elmo-model.h5')  \n",
    "    predicts = model.predict(x_test, batch_size=128)\n",
    "\n",
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125  52   2  44   8]\n",
      " [171 142  13 154  25]\n",
      " [ 61  66  12 189  45]\n",
      " [ 26  50  11 292 151]\n",
      " [ 12   7   1 106 164]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.54      0.40       231\n",
      "           2       0.45      0.28      0.35       505\n",
      "           3       0.31      0.03      0.06       373\n",
      "           4       0.37      0.55      0.44       530\n",
      "           5       0.42      0.57      0.48       290\n",
      "\n",
      "   micro avg       0.38      0.38      0.38      1929\n",
      "   macro avg       0.37      0.39      0.35      1929\n",
      "weighted avg       0.38      0.38      0.34      1929\n",
      "\n",
      "Accuracy of ELMO is: 0.3810264385692068\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4\n",
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__) \n",
    "print(keras.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">** Past Work mentioned on this dataset at max achieved 95.22 accuracies. keras with ELMO embeddings achieved 95.5. But still BERT base model without any preprocessing and achieved 97.75 accuracies.\n",
    "\n",
    "[bert model]https://www.kaggle.com/sarthak221995/textclassification-97-77-accuracy-bert\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Future Improvements on this kernel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Explore preprocessing steps on data.\n",
    "* Explore other models as baseline.\n",
    "* Make this notebook more informative and illustrative.\n",
    "* Explaination on ELMO Embeddings Model.\n",
    "* More time on data exploration\n",
    "and many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This kernel is based on the work of http://hunterheidenreich.com/blog/elmo-word-vectors-in-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

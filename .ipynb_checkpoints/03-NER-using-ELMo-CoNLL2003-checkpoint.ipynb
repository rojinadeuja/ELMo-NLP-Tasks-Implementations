{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "22mElNLo6rUI",
    "outputId": "88728735-fa24-4d6a-a876-009b01c86334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_275\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_275-8u275-b01-0ubuntu1~18.04-b01)\n",
      "OpenJDK 64-Bit Server VM (build 25.275-b01, mixed mode)\n",
      "Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.7\n",
      "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "py4j",
         "pyspark"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spark-nlp\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/1d/9a2a7c17fc3b3aa78b3921167feed4911d5a055833fea390e7741bba0870/spark_nlp-2.6.5-py2.py3-none-any.whl\n",
      "Installing collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-2.6.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "com",
         "sparknlp"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_QE6hqA4WHh"
   },
   "source": [
    "# NER classifier with ELMO embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wybDus1P4WHk"
   },
   "source": [
    "## Load CoNLL2003 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EA0QHrLF4WHl",
    "outputId": "bf1c4775-eb22-4543-b50f-be4a56744c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already present.\n"
     ]
    }
   ],
   "source": [
    "# Download CoNLL 2003 Dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "download_path = \"./eng.train\"\n",
    "\n",
    "\n",
    "if not Path(download_path).is_file():\n",
    "    print(\"File Not found will downloading it!\")\n",
    "    url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.train\"\n",
    "    urllib.request.urlretrieve(url, download_path)\n",
    "else:\n",
    "    print(\"File already present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYZhNUVH4WHs"
   },
   "source": [
    "# Read data into Spark dataframe and generate features for futures tasks\n",
    "The readDataset method of the CoNLL class handily adds all the features required in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQExmc684WHu",
    "outputId": "318b3469-4360-4f3c-8190-b422f7a916e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
      "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
      "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
      "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|\n",
      "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|\n",
      "|Spanish Farm Mini...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 6, Sp...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|                   .|[[document, 0, 0,...|[[document, 0, 0,...|[[token, 0, 0, .,...|[[pos, 0, 0, ., [...|[[named_entity, 0...|\n",
      "|Only France and B...|[[document, 0, 52...|[[document, 0, 52...|[[token, 0, 3, On...|[[pos, 0, 3, RB, ...|[[named_entity, 0...|\n",
      "|The EU 's scienti...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|Sheep have long b...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 4, Sh...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "|British farmers d...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Br...|[[pos, 0, 6, JJ, ...|[[named_entity, 0...|\n",
      "|\" What we have to...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
      "|Bonn has led effo...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 3, Bo...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
      "|Germany imported ...|[[document, 0, 84...|[[document, 0, 84...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|It brought in 4,2...|[[document, 0, 82...|[[document, 0, 82...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.training import CoNLL\n",
    "\n",
    "spark = sparknlp.start()\n",
    "training_data = CoNLL().readDataset(spark, './eng.train')\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JF9dJWoW4WH6"
   },
   "source": [
    "# Define NER Pipeline \n",
    "\n",
    "### This pipeline defines a pretrained elmo component and a trainable NerDLApproach which is based on the Char CNN - BiLSTM - CRF\n",
    "\n",
    "Usually we have to add additional pipeline components before the elmo for the document, sentence and token columns. But CoNLL took already care of this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0xFttkH4WH7",
    "outputId": "86d43a71-44e9-4a69-dc53-e2daea1482c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "# Define the pretrained Elmo model. \n",
    "# We need to set lstm_outputs2 pooling layer, because the elmo layer is not yet compatible with NerDL\n",
    "elmo = ElmoEmbeddings.pretrained().setPoolingLayer(\"lstm_outputs2\") \\\n",
    " .setInputCols(\"sentence\", \"token\")\\\n",
    " .setOutputCol(\"elmo\")\\\n",
    "\n",
    "\n",
    "# Defien the Char CNN - BiLSTM - CRF model. We will feed it the Elmo tokens \n",
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"elmo\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(1)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(0)\n",
    "\n",
    "# put everything into the pipe\n",
    "pipeline = Pipeline(stages = [elmo , nerTagger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpcIr8b_4WIB"
   },
   "source": [
    "# Fit the Pipeline and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hDKsFDRy4WIC"
   },
   "outputs": [],
   "source": [
    "elmo_model = pipeline.fit(training_data.limit(10))\n",
    "# elmo_model = pipeline.fit(training_data).transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5pM7okzlzd0f"
   },
   "outputs": [],
   "source": [
    "elmo_model.stages[1].write().save('NER_elmo_20200221')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lW7bDHKd_euY"
   },
   "outputs": [],
   "source": [
    "loaded_ner_model = NerDLModel.load(\"NER_elmo_20200221\")\\\n",
    "   .setInputCols([\"sentence\", \"token\", \"elmo\"])\\\n",
    "   .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Jh7rNYyN_jOL"
   },
   "outputs": [],
   "source": [
    "document = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "sentence = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\n",
    "token = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQmEUr3XAFFY",
    "outputId": "5f14ab13-7504-45fe-86c1-cefa4456785f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "elmo = ElmoEmbeddings.pretrained().setPoolingLayer(\"lstm_outputs2\") \\\n",
    " .setInputCols(\"sentence\", \"token\")\\\n",
    " .setOutputCol(\"elmo\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "odLjvLYEAPy3"
   },
   "outputs": [],
   "source": [
    "loaded_ner_model = NerDLModel.load(\"NER_elmo_20200221\")\\\n",
    "   .setInputCols([\"sentence\", \"token\", \"elmo\"])\\\n",
    "   .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XiUKCDZwAk2H"
   },
   "outputs": [],
   "source": [
    "converter = NerConverter()\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "    .setOutputCol(\"ner_span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Itm8mNArAa0G"
   },
   "outputs": [],
   "source": [
    "custom_ner_pipeline = Pipeline(\n",
    "    stages = [\n",
    "              document,\n",
    "              sentence,\n",
    "              token,\n",
    "              elmo,\n",
    "              loaded_ner_model,\n",
    "              converter\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFSKuv-x4WIH"
   },
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ObW2xBPn4WII"
   },
   "outputs": [],
   "source": [
    "# ner_df.select(*['text', 'ner']).limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "CAGIS-vS4WIO"
   },
   "outputs": [],
   "source": [
    "text = \"Peter Parker is a nice man and lives in New York\"\n",
    "prediction_data = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7zKnSsfAvqb",
    "outputId": "3083ee78-a8f1-46f6-b044-4448fe7c7ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                elmo|                 ner|            ner_span|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Peter Parker is a...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 4, Pe...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 0, 4, Pe...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_model = custom_ner_pipeline.fit(prediction_data)\n",
    "preds = prediction_model.transform(prediction_data)\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3go6kSqrC3VQ",
    "outputId": "175079e6-e841-4b54-d107-5055b898bf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+-----------------------------------------+\n",
      "|result                                                      |result                                   |\n",
      "+------------------------------------------------------------+-----------------------------------------+\n",
      "|[Peter, Parker, is, a, nice, man, and, lives, in, New, York]|[I-PER, O, O, I-PER, O, O, O, O, O, O, O]|\n",
      "+------------------------------------------------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results in readable format\n",
    "preds.select(\"token.result\",\"ner.result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOSh2klXA1vB",
    "outputId": "a6a73469-e899-48f8-fca2-f7ddf0ef9f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|chunk|entity|\n",
      "+-----+------+\n",
      "|Peter|PER   |\n",
      "|a    |PER   |\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show identified NERs only\n",
    "import pyspark.sql.functions as F\n",
    "preds.select(F.explode(F.arrays_zip(\"ner_span.result\", \"ner_span.metadata\")).alias(\"entities\"))\\\n",
    ".select(F.expr(\"entities['0']\").alias(\"chunk\"), F.expr(\"entities['1'].entity\").alias(\"entity\")).\\\n",
    "show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PA6K8AR_CUSu",
    "outputId": "5989eece-78c1-45a7-bc9a-cc8580d81160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Not found will downloading it!\n"
     ]
    }
   ],
   "source": [
    "# Download CoNLL 2003 Dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "download_path = \"./eng.testa\"\n",
    "\n",
    "\n",
    "if not Path(download_path).is_file():\n",
    "    print(\"File Not found will downloading it!\")\n",
    "    url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.testa\"\n",
    "    urllib.request.urlretrieve(url, download_path)\n",
    "else:\n",
    "    print(\"File already present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n64AWt3OP3Bm",
    "outputId": "c8556fa3-830a-4bcd-cd51-57279dd225b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|\n",
      "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
      "|Their stay on top...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 4, Th...|[[pos, 0, 4, PRP$...|[[named_entity, 0...|\n",
      "|After bowling Som...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|\n",
      "|Trailing by 213 ,...|[[document, 0, 12...|[[document, 0, 12...|[[token, 0, 7, Tr...|[[pos, 0, 7, VBG,...|[[named_entity, 0...|\n",
      "|Essex , however ,...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 4, Es...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "|Hussain , conside...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 6, Hu...|[[pos, 0, 6, NN, ...|[[named_entity, 0...|\n",
      "|By the close York...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|\n",
      "|At the Oval , Sur...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 1, At...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|\n",
      "|He was well backe...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|Derbyshire kept u...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 9, De...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|\n",
      "|Australian Tom Mo...|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 9, Au...|[[pos, 0, 9, NNP,...|[[named_entity, 0...|\n",
      "|After the frustra...|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|\n",
      "|They were held up...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 3, Th...|[[pos, 0, 3, PRP,...|[[named_entity, 0...|\n",
      "|By stumps Kent ha...|[[document, 0, 41...|[[document, 0, 41...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|\n",
      "|CRICKET - ENGLISH...|[[document, 0, 45...|[[document, 0, 45...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|\n",
      "|Result and close ...|[[document, 0, 81...|[[document, 0, 81...|[[token, 0, 5, Re...|[[pos, 0, 5, NN, ...|[[named_entity, 0...|\n",
      "|Leicester : Leice...|[[document, 0, 67...|[[document, 0, 67...|[[token, 0, 8, Le...|[[pos, 0, 8, JJ, ...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9VYbNWeRFLj",
    "outputId": "5479fe7d-7c94-4e58-b697-f6fbcb49916b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|                elmo|                 ner|            ner_span|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|Their stay on top...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 4, Th...|[[pos, 0, 4, PRP$...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|After bowling Som...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|Trailing by 213 ,...|[[document, 0, 12...|[[document, 0, 12...|[[token, 0, 7, Tr...|[[pos, 0, 7, VBG,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 31, 31, ...|\n",
      "|Essex , however ,...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 4, Es...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|Hussain , conside...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 6, Hu...|[[pos, 0, 6, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|By the close York...|[[document, 0, 20...|[[document, 0, 20...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|At the Oval , Sur...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 1, At...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 3, 5, th...|\n",
      "|He was well backe...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|Derbyshire kept u...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 9, De...|[[pos, 0, 9, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|Australian Tom Mo...|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 9, Au...|[[pos, 0, 9, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 113, 113...|\n",
      "|After the frustra...|[[document, 0, 15...|[[document, 0, 15...|[[token, 0, 4, Af...|[[pos, 0, 4, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 6, 8, th...|\n",
      "|They were held up...|[[document, 0, 11...|[[document, 0, 11...|[[token, 0, 3, Th...|[[pos, 0, 3, PRP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 15, 16, ...|\n",
      "|By stumps Kent ha...|[[document, 0, 41...|[[document, 0, 41...|[[token, 0, 1, By...|[[pos, 0, 1, IN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|CRICKET - ENGLISH...|[[document, 0, 45...|[[document, 0, 45...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|Result and close ...|[[document, 0, 81...|[[document, 0, 81...|[[token, 0, 5, Re...|[[pos, 0, 5, NN, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "|Leicester : Leice...|[[document, 0, 67...|[[document, 0, 67...|[[token, 0, 8, Le...|[[pos, 0, 8, JJ, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|                  []|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = prediction_model.transform(test_data)\n",
    "test_preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbMheh0vPflA",
    "outputId": "38a443c3-2447-4bc1-96c1-ea9918d1717d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                                                                                                                                        |result                                                                                                                         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, TOP, AFTER, INNINGS, VICTORY, .]                                                                                                                                                                                 |[O, O, O, O, O, O, O, O, O, O, O]                                                                                              |\n",
      "|[LONDON, 1996-08-30]                                                                                                                                                                                                                                          |[O, O]                                                                                                                         |\n",
      "|[West, Indian, all-rounder, Phil, Simmons, took, four, for, 38, on, Friday, as, Leicestershire, beat, Somerset, by, an, innings, and, 39, runs, in, two, days, to, take, over, at, the, head, of, the, county, championship, .]                               |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                      |\n",
      "|[Their, stay, on, top, ,, though, ,, may, be, short-lived, as, title, rivals, Essex, ,, Derbyshire, and, Surrey, all, closed, in, on, victory, while, Kent, made, up, for, lost, time, in, their, rain-affected, match, against, Nottinghamshire, .]          |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                |\n",
      "|[After, bowling, Somerset, out, for, 83, on, the, opening, morning, at, Grace, Road, ,, Leicestershire, extended, their, first, innings, by, 94, runs, before, being, bowled, out, for, 296, with, England, discard, Andy, Caddick, taking, three, for, 83, .]|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]             |\n",
      "|[Trailing, by, 213, ,, Somerset, got, a, solid, start, to, their, second, innings, before, Simmons, stepped, in, to, bundle, them, out, for, 174, .]                                                                                                          |[O, O, O, O, O, O, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                   |\n",
      "|[Essex, ,, however, ,, look, certain, to, regain, their, top, spot, after, Nasser, Hussain, and, Peter, Such, gave, them, a, firm, grip, on, their, match, against, Yorkshire, at, Headingley, .]                                                             |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                     |\n",
      "|[Hussain, ,, considered, surplus, to, England, ', s, one-day, requirements, ,, struck, 158, ,, his, first, championship, century, of, the, season, ,, as, Essex, reached, 372, and, took, a, first, innings, lead, of, 82, .]                                 |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                      |\n",
      "|[By, the, close, Yorkshire, had, turned, that, into, a, 37-run, advantage, but, off-spinner, Such, had, scuttled, their, hopes, ,, taking, four, for, 24, in, 48, balls, and, leaving, them, hanging, on, 119, for, five, and, praying, for, rain, .]         |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]          |\n",
      "|[At, the, Oval, ,, Surrey, captain, Chris, Lewis, ,, another, man, dumped, by, England, ,, continued, to, silence, his, critics, as, he, followed, his, four, for, 45, on, Thursday, with, 80, not, out, on, Friday, in, the, match, against, Warwickshire, .]|[O, I-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]|\n",
      "|[He, was, well, backed, by, England, hopeful, Mark, Butcher, who, made, 70, as, Surrey, closed, on, 429, for, seven, ,, a, lead, of, 234, .]                                                                                                                  |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                    |\n",
      "|[Derbyshire, kept, up, the, hunt, for, their, first, championship, title, since, 1936, by, reducing, Worcestershire, to, 133, for, five, in, their, second, innings, ,, still, 100, runs, away, from, avoiding, an, innings, defeat, .]                       |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                         |\n",
      "|[Australian, Tom, Moody, took, six, for, 82, but, Chris, Adams, ,, 123, ,, and, Tim, O'Gorman, ,, 109, ,, took, Derbyshire, to, 471, and, a, first, innings, lead, of, 233, .]                                                                                |[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, I-PER, O, O, O, O, O, O]                              |\n",
      "|[After, the, frustration, of, seeing, the, opening, day, of, their, match, badly, affected, by, the, weather, ,, Kent, stepped, up, a, gear, to, dismiss, Nottinghamshire, for, 214, .]                                                                       |[O, I-LOC, O, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                   |\n",
      "|[They, were, held, up, by, a, gritty, 84, from, Paul, Johnson, but, ex-England, fast, bowler, Martin, McCague, took, four, for, 55, .]                                                                                                                        |[O, O, O, I-LOC, O, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                     |\n",
      "|[By, stumps, Kent, had, reached, 108, for, three, .]                                                                                                                                                                                                          |[O, O, O, O, O, O, O, O, O]                                                                                                    |\n",
      "|[CRICKET, -, ENGLISH, COUNTY, CHAMPIONSHIP, SCORES, .]                                                                                                                                                                                                        |[O, O, O, O, O, O, O]                                                                                                          |\n",
      "|[LONDON, 1996-08-30]                                                                                                                                                                                                                                          |[O, O]                                                                                                                         |\n",
      "|[Result, and, close, of, play, scores, in, English, county, championship, matches, on, Friday, :]                                                                                                                                                             |[O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                                                     |\n",
      "|[Leicester, :, Leicestershire, beat, Somerset, by, an, innings, and, 39, runs, .]                                                                                                                                                                             |[O, O, O, O, O, O, O, O, O, O, O, O]                                                                                           |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds.select(\"token.result\",\"ner.result\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ner_elmo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "name": "NER-Tutorial",
  "notebookId": 3359671281044291
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
